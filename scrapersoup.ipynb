{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image, ImageChops\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "categories = open('categories.txt').read().splitlines()[:2]\n",
    "target_images_per_category = 500\n",
    "\n",
    "size_requirements = {\n",
    "    '1:1': [(640, 640), (416, 416)],\n",
    "    '4:3': [(1024, 768)],\n",
    "    '16:9': [(1280, 720)]\n",
    "}\n",
    "\n",
    "# Create directories for each category\n",
    "for category in categories:\n",
    "    os.makedirs(f'images/{category}', exist_ok=True)\n",
    "\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_black_image(img):\n",
    "    extrema = img.convert(\"L\").getextrema()\n",
    "    return extrema[0] == extrema[1]\n",
    "\n",
    "def has_watermark(img):\n",
    "    # Simple heuristic: check for transparency or large uniform areas\n",
    "    if img.mode in ('RGBA', 'LA'):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url, category):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        img_format = img.format.lower()\n",
    "        if img_format not in ['png', 'jpg', 'jpeg']:\n",
    "            return None\n",
    "\n",
    "        # Check image size\n",
    "        width, height = img.size\n",
    "        if (width, height) not in size_requirements['1:1'] and \\\n",
    "           (width, height) not in size_requirements['4:3'] and \\\n",
    "           (width, height) not in size_requirements['16:9']:\n",
    "            return None\n",
    "\n",
    "        # Data cleaning\n",
    "        if is_black_image(img) or has_watermark(img):\n",
    "            return None\n",
    "\n",
    "        # Save image\n",
    "        img_hash = hashlib.md5(response.content).hexdigest()\n",
    "        img_path = f'images/{category}/{img_hash}.{img_format}'\n",
    "        img.save(img_path)\n",
    "\n",
    "        # Return metadata\n",
    "        return {\n",
    "            'image_url': url,\n",
    "            'source': 'web',\n",
    "            'download_time': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'file_path': img_path\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download image from {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_images(category):\n",
    "    url = f'https://www.pexels.com/search/{category}/'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    img_tags = soup.find_all('img')\n",
    "    print(f\"Found {len(img_tags)} images for category) {category}\")\n",
    "    metadata = []\n",
    "    for img_tag in img_tags:\n",
    "        img_url = img_tag.get('src')\n",
    "        if img_url:\n",
    "            data = download_image(img_url, category)\n",
    "            if data:\n",
    "                metadata.append(data)\n",
    "                if len(metadata) >= target_images_per_category:\n",
    "                    break\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "all_metadata = []\n",
    "for category in categories:\n",
    "    print(f\"Scraping images for category: {category}\")\n",
    "    metadata = scrape_images(category)\n",
    "    for data in metadata:\n",
    "        data['category'] = category\n",
    "    all_metadata.extend(metadata)\n",
    "\n",
    "# Save metadata to CSV\n",
    "df = pd.DataFrame(all_metadata)\n",
    "df.to_csv('image_metadata.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
