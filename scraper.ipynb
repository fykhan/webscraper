{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import requests\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = open('categories.txt').read().splitlines()[:2]\n",
    "OUTPUT_DIR = 'images'\n",
    "MAX_IMAGES_PER_CATEGORY = 500\n",
    "CSV_FILE = 'image_metadata.csv'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CSV_FILE, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['category', 'image_url', 'download_time', 'file_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url, category):\n",
    "    try:\n",
    "        if not url.startswith('http'):\n",
    "            return False\n",
    "        response = requests.get(url, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "            if image.mode in (\"RGB\", \"L\"):\n",
    "                file_hash = hashlib.md5(response.content).hexdigest()\n",
    "                file_name = f'{category}_{file_hash}.jpg'\n",
    "                file_path = os.path.join(OUTPUT_DIR, file_name)\n",
    "                image.save(file_path)\n",
    "\n",
    "                # Save metadata\n",
    "                with open(CSV_FILE, mode='a', newline='') as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow([category, url, datetime.now(), file_path])\n",
    "                return True\n",
    "    except Exception as e:\n",
    "        print(f'Failed to download {url}: {str(e)}')\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_image_urls(query):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')  # Run Chrome in headless mode\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    search_url = f'https://www.google.com/search?q={query}&tbm=isch'\n",
    "    driver.get(search_url)\n",
    "    time.sleep(5)\n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    driver.quit()\n",
    "\n",
    "    image_urls = []\n",
    "    for a in soup.find_all:\n",
    "        try:\n",
    "            img_url = img.get_attribute('src')\n",
    "            if img_url and img_url.startswith('http') and not img_url.endswith('.svg'):\n",
    "                image_urls.append(img_url)\n",
    "        except:\n",
    "            continue\n",
    "    return image_urls\n",
    "\n",
    "\n",
    "def scrape_images():\n",
    "    for category in CATEGORIES:\n",
    "        query = category.replace(' ', '+')\n",
    "        print(f'Scraping images for: {category}')\n",
    "        image_urls = get_image_urls(query)\n",
    "\n",
    "        count = 0\n",
    "        for img_url in image_urls:\n",
    "            if download_image(img_url, category):\n",
    "                count += 1\n",
    "                if count >= MAX_IMAGES_PER_CATEGORY:\n",
    "                    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping images for: person\n",
      "Scraping images for: bicycle\n"
     ]
    }
   ],
   "source": [
    "scrape_images()\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
