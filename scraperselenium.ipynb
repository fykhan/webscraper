{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import requests\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'trains', 'truck', 'boat', 'traffic', 'light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "CATEGORIES = open('categories.txt').readlines()\n",
    "CATEGORIES = [x.strip() for x in CATEGORIES]\n",
    "print(CATEGORIES)\n",
    "OUTPUT_DIR = 'images'\n",
    "MAX_IMAGES_PER_CATEGORY = 500\n",
    "CSV_FILE = 'image_metadata.csv'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "options = Options()\n",
    "options.add_argument('--headless')  # Run Chrome in headless mode\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CSV_FILE, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['category', 'image_url', 'download_time', 'file_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_load_more():\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    scroll_count = 0\n",
    "    while scroll_count < 15:  # Scroll 15 times only\n",
    "        try:\n",
    "            load_more_button = driver.find_element(By.CSS_SELECTOR, 'button.cDy10.vbbXa.XKj1X.aZVYw.vqRTY.vGtHf.s5zyR.nwXgM.pYP1f')\n",
    "            load_more_button.click()\n",
    "            time.sleep(3)  # Wait for new images to load\n",
    "        except:\n",
    "            pass  # No more 'Load More' button found, continue scrolling\n",
    "\n",
    "        # Scroll to bottom of the page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(3)\n",
    "\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        print(f'Scrolled {scroll_count + 1} times')\n",
    "        last_height = new_height\n",
    "        scroll_count += 1\n",
    "\n",
    "def extract_image_urls(driver):\n",
    "    with open(\"page_content.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(BeautifulSoup(driver.page_source).prettify())\n",
    "    \n",
    "    img_elements = driver.find_elements(By.CSS_SELECTOR, 'img.czQTa')\n",
    "\n",
    "    img_urls = set()\n",
    "    for img in img_elements:\n",
    "        src = img.get_attribute('src')\n",
    "        srcset = img.get_attribute('srcset')\n",
    "\n",
    "        if src and 'https://images.unsplash.com/' in src:\n",
    "            img_urls.add(src)\n",
    "\n",
    "        if srcset:\n",
    "            urls = [url.split(' ')[0] for url in srcset.split(',')]  \n",
    "            if urls:\n",
    "                img_urls.add(urls[-1])  \n",
    "    return img_urls\n",
    "\n",
    "def download_image(url, category):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "            file_hash = hashlib.md5(response.content).hexdigest()\n",
    "            file_name = f'{category}/{file_hash}.jpg'\n",
    "            file_path = os.path.join(OUTPUT_DIR, file_name)\n",
    "            if not os.path.exists(file_path):\n",
    "                image.save(file_path)\n",
    "            else:\n",
    "                print(f'Image already exists: {file_path}')\n",
    "            \n",
    "            with open(CSV_FILE, mode='a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([category, url, datetime.now(), file_path])\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f'Failed to download {url}: {e}')\n",
    "    return False\n",
    "\n",
    "\n",
    "def scrape_images():\n",
    "    for category in CATEGORIES:\n",
    "        query = category.strip().replace(' ', '-')\n",
    "        url = f'https://unsplash.com/s/photos/{query}'\n",
    "\n",
    "        print(f'Scraping images for: {query}')\n",
    "        driver.get(url)\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Click 'Load More' repeatedly to reveal all images\n",
    "        click_load_more()\n",
    "\n",
    "        # Extract image URLs\n",
    "        img_urls = extract_image_urls(driver)\n",
    "        print(f'Found {len(img_urls)} images for category: {category}')\n",
    "\n",
    "        count = 0\n",
    "        for img_url in img_urls:\n",
    "            if download_image(img_url, query):\n",
    "                count += 1\n",
    "                if count >= MAX_IMAGES_PER_CATEGORY:\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping images for: person\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scrape_images()\n\u001b[0;32m      2\u001b[0m driver\u001b[38;5;241m.\u001b[39mquit()\n",
      "Cell \u001b[1;32mIn[36], line 75\u001b[0m, in \u001b[0;36mscrape_images\u001b[1;34m()\u001b[0m\n\u001b[0;32m     72\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Click 'Load More' repeatedly to reveal all images\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m click_load_more()\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Extract image URLs\u001b[39;00m\n\u001b[0;32m     78\u001b[0m img_urls \u001b[38;5;241m=\u001b[39m extract_image_urls(driver)\n",
      "Cell \u001b[1;32mIn[36], line 14\u001b[0m, in \u001b[0;36mclick_load_more\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Scroll to bottom of the page\u001b[39;00m\n\u001b[0;32m     13\u001b[0m driver\u001b[38;5;241m.\u001b[39mexecute_script(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow.scrollTo(0, document.body.scrollHeight);\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     16\u001b[0m new_height \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mexecute_script(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn document.body.scrollHeight\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_height \u001b[38;5;241m==\u001b[39m last_height:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scrape_images()\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
